{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-0ba676cd-8fe9-491b-bb82-6dc8dcd04578",
    "deepnote_cell_type": "markdown",
    "id": "vwfx12QMKDU1"
   },
   "source": [
    "<img src=\"https://apps.novasbe.pt/NovaMobility/resources/assets/images/nova_logo.png\" width=\"300\">\n",
    "<author = \"Claudio Haupt Vieira\">\n",
    "<license = \"https://creativecommons.org/licenses/by-nc/3.0/\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-c040548d-444a-414b-b3e8-7467dc0a6cce",
    "deepnote_cell_type": "markdown",
    "id": "0WWq1ESXKDVA"
   },
   "source": [
    "# Exercises Functions - Sentiment Analysis on cryptocurrency headline dataset\n",
    "\n",
    "Sentiment analysis techniques allow identifying emotional dimensions from pieces of text of natural languages. While it is an obvious task for a human reader, it is significantly harder task for computers to perform, as strings exist as binary code in computer memory and have no inherent meaning. \n",
    "\n",
    "How can we compute sentiment from strings? Humans have to inform computers on how \"positive\" or \"negative\" a given word is. Fortunately, there are several crowdsourced efforts of word sentiment annotation, which are freely available and are relatively easy to use!\n",
    "\n",
    "In this assignment you will leverage your knowledge on Python functions and dictionaries in order to obtain the sentiment of news articles related to cryptocurrencies, which pricing is largely determined by collective mood.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-40ecbae2-94f2-48d3-8a27-7224d8e17dd8",
    "deepnote_cell_type": "markdown",
    "id": "qBKiZwFjKDVB"
   },
   "source": [
    "The dataset consists of ~190k cryptocurrency news headlines extracted from several different online media, from 2013 to 2017, mostly from english sources. The data is structured as list of dicts, where each dict contains two keys: `publishdate` and `headlinetext`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN THIS CELL TO LOAD THE DATASET\n",
    "### MAKE SURE THE FILES IN THE ZIP FOLDER ALL ALL IN THE FOLDER OF THIS NOTEBOOK\n",
    "import pandas as pd\n",
    "from typing import Callable, List, Union\n",
    "import os\n",
    "\n",
    "def load_news_dataset(\n",
    "    path: str = \"./crypto_headlines.csv\", to_df=False) -> Union[List[dict], pd.DataFrame]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(\n",
    "            \"Ensure crypto_headlines.csv is in same folder as ipynb.\"\n",
    "        )\n",
    "    data = pd.read_csv(path, sep=\"\\t\", index_col=False)\n",
    "    data = data.to_dict(\"records\") if not to_df else data\n",
    "    return data\n",
    "\n",
    "news = load_news_dataset()  # Run this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00006-6c49ec85-96bd-48f3-a507-b60560c550d4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1617235802794,
    "id": "dT0NZhIsKDVC",
    "outputId": "1bbf3656-e033-4548-bbac-a23da0b41335",
    "source_hash": "af508b4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'publishdate': 20130504,\n",
       "  'headlinetext': 'COnSTELlATIon DaG iS nOW liStEd On kucoiN eXC?haNGE'},\n",
       " {'publishdate': 20130511,\n",
       "  'headlinetext': 'ItA*lys cRypTOCUrREnCy BITgrAil suspeNds OpERatIOnS'},\n",
       " {'publishdate': 20130511,\n",
       "  'headlinetext': 'THe diffeRENCe bETWEEn sHarEs aNd cRYpToCUrReNâ‚¬CiES'},\n",
       " {'publishdate': 20130512,\n",
       "  'headlinetext': 'fedS seIzE 47 mIlLION In bItCoinS in FAke ID ST=ing'},\n",
       " {'publishdate': 20130514,\n",
       "  'headlinetext': 'ThE diG sTarteD ASiCboOST neTwORK AnD b@ItcoIN cAsH'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-342ac045-4cef-44a8-83f6-89c3dada8c79",
    "deepnote_cell_type": "markdown",
    "id": "whMa9SDCKDVE"
   },
   "source": [
    "The headlines text obviously needs to be fixed! While the headlines are readable for a human, in programming strings are case-sensitive, e.g. \"bItCoinS\" is not equal to \"bitcoins\".\n",
    "\n",
    "In the first part of the assignment you will create four functions that should be able to help with cleaning natural language strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-73671736-7fdb-4402-b489-cb574e5670ed",
    "deepnote_cell_type": "markdown",
    "id": "FYBj7q-yKDVF"
   },
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-dc18ca17-04ef-4feb-94bc-e1dd0911ad5e",
    "deepnote_cell_type": "markdown",
    "id": "XJUDzc_3KDVF"
   },
   "source": [
    "## Exercise 1 - Cleaning strings\n",
    "\n",
    "### Description\n",
    "\n",
    "Human-generated text data generally is generally noisy. Before obtaining sentiment from strings, we have to ensure strings are in its simplest possible form.\n",
    "\n",
    "If we are given a noisy string, such as:\n",
    "\n",
    "```python\n",
    "\"LUKE!!11!!1! I am your father...\"\n",
    "```\n",
    "\n",
    "a cleaned string would look like:\n",
    "\n",
    "```python\n",
    "\"luke i am your father\"\n",
    "```\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Write a function, `clean_string` with the following requirements:\n",
    "\n",
    "- should have one string argument\n",
    "- should return lowercase string with only alphabetical (a-z) characters and spaces (\" \")\n",
    "\n",
    "Note that `clean_string` should always return a string, even if we provide an empty string as input.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```ipython\n",
    "clean_string(\"THERE IS NO SPOON!\")\n",
    ">> \"there is no spoon\"\n",
    "\n",
    "clean_string(\"\")\n",
    ">> \"\"\n",
    "```\n",
    "\n",
    "Hints:\n",
    "- [str alphabetical](https://stackoverflow.com/questions/15558392/how-can-i-check-if-character-in-a-string-is-a-letter-python)\n",
    "- [str lowercase](https://stackoverflow.com/questions/6797984/how-do-i-lowercase-a-string-in-python)\n",
    "- Work on a new string (You can create empty strings!) rather than change the input string \n",
    "- Pay attention to the spaces:\n",
    "```python\n",
    "space = ' '\n",
    "space.isalpha()\n",
    ">> False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00010-9ed5cbf5-b707-4699-9cbb-c58ec7ba442c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1617234959351,
    "id": "RahYtdFjKDVG",
    "source_hash": "9d036e75"
   },
   "outputs": [],
   "source": [
    "# solve ex1 here\n",
    "def clean_string(string):\n",
    "    string = string.lower()\n",
    "    newstring = \"\"\n",
    "    for char in string:\n",
    "        if char.isalpha() or char == \" \":\n",
    "            newstring += char\n",
    "    return newstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-a72d36fc-8540-402a-b6f7-f577779b3139",
    "deepnote_cell_type": "markdown",
    "id": "uh6ey7R-QehE"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-9b8aaa1d-f549-4aa9-8daa-9ad721ca9a0b",
    "deepnote_cell_type": "markdown",
    "id": "PHOB-0OzKDVH"
   },
   "source": [
    "## Exercise 2 - Tokenization\n",
    "\n",
    "### Description\n",
    "\n",
    "Words are the main unit of natural language, but our strings contain whole sentences. Each sentence string should be split by its words.\n",
    "\n",
    "\n",
    "### Instructions\n",
    "In this exercise you will write a function `tokenize` that given a string, will split (at spaces) the string into a list of its substrings.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```python\n",
    "tokenize(\"hello darkness my old friend\")\n",
    ">> [\"hello\", \"darkness\", \"my\", \"old\", \"friend\"]\n",
    "\n",
    "tokenize(\"hello, world\")\n",
    ">> [\"hello,\", \"world\"]\n",
    "\n",
    "tokenize(\"\")\n",
    ">> []\n",
    "```\n",
    "\n",
    "\n",
    "Hint: \n",
    "- [str.split](https://www.datacamp.com/community/tutorials/python-string-split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00014-d75b57eb-5558-4995-8f8a-0343e0485f9d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1617234959365,
    "id": "G5li0r01KDVI",
    "source_hash": "6d73ee44"
   },
   "outputs": [],
   "source": [
    "# solve ex2 here.\n",
    "def tokenize(string):\n",
    "    return string.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-ba0eec36-7572-45c2-bf81-f6a6db772910",
    "deepnote_cell_type": "markdown",
    "id": "IlIA-pUxQcqM"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-202da678-7348-4444-8646-8203c244f1ee",
    "deepnote_cell_type": "markdown",
    "id": "csP9B4jtKDVK"
   },
   "source": [
    "## Exercise 3 - Preprocessing function\n",
    "\n",
    "### Description\n",
    "We got two functions that apply transformations on strings and can work in chain - what we call function pipeline, where the output of one function serves as the input of the next function. So, instead of having these two functions, we can pipeline these into a single function that can preprocess any given string.\n",
    "\n",
    "What is pipelining? For example, the following code chains two functions, `add` and `divide_by_10`, wrapped in the pipeline `add_divide_by_10` function.\n",
    "\n",
    "```ipython\n",
    "def add(num1, num2):\n",
    "    return num1 + num2\n",
    "\n",
    "def divide_by_10(num):\n",
    "    return num / 10\n",
    "    \n",
    "def add_divide_by_10(a, b)\n",
    "    addition = add(a, b) \n",
    "    division = divide_by_10(addition)  # output of add() is input of division()\n",
    "    return division\n",
    "\n",
    "add_divide_by_10(10, 10)\n",
    ">> 2\n",
    "```\n",
    "\n",
    "\n",
    "### Instructions\n",
    " In this exercise you will define the `preprocess_string` function, with the following requirements:\n",
    " \n",
    "- accepts one string argument\n",
    "- should call two functions, `clean_string` and `tokenize`\n",
    "- should return a list with preprocessed tokens\n",
    "\n",
    "Example usage\n",
    "```python\n",
    "preprocess_string(\"Hell11o!!)\n",
    ">> [\"hello\"]\n",
    "\n",
    "preprocess_string(\"THERE IS NO SP00OON\")\n",
    ">> [\"there\", \"is\", \"no\", \"spoon\"]\n",
    "\n",
    "preprocess_string(\"\")\n",
    ">> []\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00018-1776eade-1c51-41b3-9457-403b3aa51e64",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1617234959407,
    "id": "uuYwzYSVKDVL",
    "source_hash": "b4e39d35"
   },
   "outputs": [],
   "source": [
    "# solve ex3 here\n",
    "def preprocess_string(string):\n",
    "    clean = clean_string(string)\n",
    "    return tokenize(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_string(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-10e3449f-7b94-4844-81d0-07835c5b96a0",
    "deepnote_cell_type": "markdown",
    "id": "IqnW82DNQaPq"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-2bd6cbd3-6c33-4672-a8cf-7d53682bf79a",
    "deepnote_cell_type": "markdown",
    "id": "pXcTETp4KDVN"
   },
   "source": [
    "## Exercise 4 - Storing preprocessed strings\n",
    "\n",
    "### Description\n",
    "\n",
    "We are all set to preprocess strings. Recall the `news` headlines dataset with all these noisy strings... We can clean these using the `preprocess_string` function. However, we might want to use the preprocessed strings later when performing sentiment analysis, so we should write a function to store the preprocessed strings.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "In this exercise you are going create a function `add_preprocessed_headlines` with the following requirements:\n",
    "- accepts one `list` argument, named `dataset`  \n",
    "- assuming there are `dicts` in the input `dataset` list, add the key `proc_headlinetext`, where the value is the output of the `preprocess_string` function on `headlinetext`.\n",
    "- return the updated list of dicts. \n",
    "\n",
    "Finally, **run the function on `news` dataset, and store the result to `proc_news` variable**.\n",
    "\n",
    "Example dict record:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"publishdate\": 20130504,\n",
    "        \"headlinetext\": \"ItA*lys cRypTOCUrREnCy BITgrAil suspeNds OpERatIOnS\",\n",
    "        \"proc_headlinetext\": [\n",
    "            \"italys\",\n",
    "            \"cryptocurrency\",\n",
    "            \"bitgrail\",\n",
    "            \"suspends\",\n",
    "            \"operations\",\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00022-1ffc6ce2-3371-458f-bdf9-328fac73a5b2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3657,
    "execution_start": 1617234959416,
    "source_hash": "9b648a23"
   },
   "outputs": [],
   "source": [
    "# solve ex4 here\n",
    "def add_preprocessed_headlines(dataset):\n",
    "    preprocessed_string = []\n",
    "    for dict in dataset:\n",
    "        dict[\"proc_headlinetext\"] = preprocess_string(dict[\"headlinetext\"]) \n",
    "        preprocessed_string.append(dict)   \n",
    "    return preprocessed_string\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_news = add_preprocessed_headlines(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'publishdate': 20130504,\n",
       "  'headlinetext': 'COnSTELlATIon DaG iS nOW liStEd On kucoiN eXC?haNGE',\n",
       "  'proc_headlinetext': ['constellation',\n",
       "   'dag',\n",
       "   'is',\n",
       "   'now',\n",
       "   'listed',\n",
       "   'on',\n",
       "   'kucoin',\n",
       "   'exchange']},\n",
       " {'publishdate': 20130511,\n",
       "  'headlinetext': 'ItA*lys cRypTOCUrREnCy BITgrAil suspeNds OpERatIOnS',\n",
       "  'proc_headlinetext': ['italys',\n",
       "   'cryptocurrency',\n",
       "   'bitgrail',\n",
       "   'suspends',\n",
       "   'operations']}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_news[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-3e0ca80a-22a6-44b4-8263-9a1f77ef4084",
    "deepnote_cell_type": "markdown",
    "id": "RVVfnMEvQVm6"
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-5817c390-8968-4c8b-8310-400f307acfc9",
    "deepnote_cell_type": "markdown",
    "id": "Y4llEDZLKDVO"
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-7d270483-1fa1-4c36-aa91-ee41247bc20a",
    "deepnote_cell_type": "markdown",
    "id": "4EhoYevMKDVO"
   },
   "source": [
    "There are a couple sentiment analysis dictionaries described in the scientific literature that are freely available [[1]](http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6006/pdf/imm6006.pdf)[[2]](https://arxiv.org/abs/1103.2903), but are typically limited to the positive-negative polarity. In this assignment we will use a more complete dictionary - the NRC Emotion Lexicon [[3]](https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm) is a dictionary of 14181 English words and their associations with eight basic emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and two sentiments (negative and positive). These annotations were manually done by crowdsourcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_sentiment_dict():\n",
    "    with open(\"sentiment.json\", \"r\") as f:\n",
    "        sentiment_dict = json.load(f)\n",
    "    return sentiment_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00027-889bc843-6558-43c4-887e-9e40bbb79b8e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 72,
    "execution_start": 1617235813447,
    "id": "eNoEjFTFKDVP",
    "source_hash": "e96cf8fd"
   },
   "outputs": [],
   "source": [
    "sentiment = load_sentiment_dict()  # Run this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-e75e36e9-ccd5-4d19-b05d-4e48dae65012",
    "deepnote_cell_type": "markdown",
    "id": "uHYXEVj6KDVP"
   },
   "source": [
    "The `sentiment` data is structured as a dict of dicts. For each of the word 14181 words in the dictionary there are 10 different keys representing sentiments, where each value is either 0 or 1, according to the annotation of a given sentiment (1) or not (0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00029-b75b83f5-38c9-4820-8b9d-cda429ac1a62",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 16,
    "execution_start": 1617235814966,
    "id": "gTXYKC6UKDVP",
    "outputId": "d42dd65a-39c6-4b6e-bdde-01951ecd3ae4",
    "source_hash": "e9e1081f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'anticipation': 1,\n",
       " 'disgust': 0,\n",
       " 'fear': 0,\n",
       " 'joy': 1,\n",
       " 'negative': 0,\n",
       " 'positive': 1,\n",
       " 'sadness': 0,\n",
       " 'surprise': 1,\n",
       " 'trust': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[\"good\"]  # \"good\" sentiment is annotated with anticipation, surprise and trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00030-e7c00d67-c6e1-4058-9d97-06f4b27555f9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1617235816719,
    "id": "smxPavtOKDVQ",
    "outputId": "4c902957-4c71-425b-d761-7649ed76b0ba",
    "source_hash": "bf80045"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 1,\n",
       " 'anticipation': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 1,\n",
       " 'joy': 0,\n",
       " 'negative': 1,\n",
       " 'positive': 0,\n",
       " 'sadness': 1,\n",
       " 'surprise': 0,\n",
       " 'trust': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[\"bad\"]  # \"bad\" sentiment is annotated with anger, disgust, negative and sadness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-ab11e9ef-aa0e-4740-8fdd-464565278c07",
    "deepnote_cell_type": "markdown",
    "id": "JYOS9MinKDVQ"
   },
   "source": [
    "So, given a sentence like `\"im mad as hell\"`, we can check each word if it is annotated in the `sentiment` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00032-57ae546e-f5da-4da3-b375-fced3ffaa31b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1617235819357,
    "id": "e-r7FCL0KDVR",
    "outputId": "e46510a9-edb7-48bf-dfc3-a1c84fe5f844",
    "source_hash": "6f9f431e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mad {'anger': 1, 'anticipation': 0, 'disgust': 1, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 0, 'trust': 0}\n",
      "hell {'anger': 1, 'anticipation': 0, 'disgust': 1, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 0, 'trust': 0}\n"
     ]
    }
   ],
   "source": [
    "for word in [\"im\", \"mad\", \"as\", \"hell\"]:\n",
    "    if word in sentiment.keys():   # confirm if word is annotated in the dictionary\n",
    "        print(word, sentiment[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-05f625fe-3664-431d-8a6e-bd042ed62a41",
    "deepnote_cell_type": "markdown",
    "id": "lQp71R67KDVR"
   },
   "source": [
    "found two matches in sentiment dict, displaying respective sentiment scores. By summation, we obtain\n",
    "\n",
    "> anger = 2, disgust = 2, fear = 2, negative = 2, sadness = 2\n",
    "\n",
    "... a very negative sentence!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-21218c67-2ce6-4e44-af4e-3b1dc2a796bf",
    "deepnote_cell_type": "markdown",
    "id": "Mrw8Qc88QQrR"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-eeec9367-d84d-4d80-ae7d-90a6f0176f9b",
    "deepnote_cell_type": "markdown",
    "id": "KYR2AjBwKDVS"
   },
   "source": [
    "## Exercise 5 - Get sentiment scores from a list of strings\n",
    "\n",
    "### Description\n",
    "We can automate sentiment extraction from any given string written in English just by looking up its words in a sentiment dict. In this exercise you will automate the sentiment analysis process using the `sentiment` dict as described above.\n",
    "\n",
    "### Instructions\n",
    "Write a function `get_sentiment` with the following requirements:\n",
    "\n",
    "- Should accept 2 arguments: \n",
    "    - a list of strings (e.g. string tokens)\n",
    "    - a word dictionary containing 10 sentiment values (like `sentiment` dict)\n",
    "- For each string in the list, it should **look for that string in the sentiment dict** and if that word is in the sentiment dict, sum the value of each sentiment of that word to the base dictionary inside the function.\n",
    "- We setup the `base` dictionary below. This function should **return the base dictionary** containing the sentiment as key, and the respective sum as value.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```ipython\n",
    "sentiment = load_sentiment_dict() \n",
    "get_sentiment([\"im\", \"mad\", \"as\", \"hell\"], sentiment)\n",
    ">> \n",
    "    {\n",
    "        \"anger\": 2,\n",
    "        \"anticipation\": 0,\n",
    "        \"disgust\": 2,\n",
    "        \"fear\": 0,\n",
    "        \"joy\": 0,\n",
    "        \"negative\": 2,\n",
    "        \"positive\": 0,\n",
    "        \"sadness\": 2,\n",
    "        \"surprise\": 0,\n",
    "        \"trust\": 0,\n",
    "    }\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00037-4e77eed8-08f2-4637-ac75-1375f14efd7e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 121,
    "execution_start": 1617234963344,
    "id": "3ZoH1hY2KDVS",
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "def get_sentiment(strings_list,sentiment):\n",
    "    \n",
    "    base = {\n",
    "        \"anger\": 0,\n",
    "        \"anticipation\": 0,\n",
    "        \"disgust\": 0,\n",
    "        \"fear\": 0,\n",
    "        \"joy\": 0,\n",
    "        \"negative\": 0,\n",
    "        \"positive\": 0,\n",
    "        \"sadness\": 0,\n",
    "        \"surprise\": 0,\n",
    "        \"trust\": 0,\n",
    "    }\n",
    "    for word in strings_list:\n",
    "        if word in sentiment.keys():\n",
    "            for key in base:\n",
    "                base[key] += sentiment[word][key]\n",
    "    return base \n",
    "    \n",
    "    # solve ex5 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 2,\n",
       " 'anticipation': 0,\n",
       " 'disgust': 2,\n",
       " 'fear': 2,\n",
       " 'joy': 0,\n",
       " 'negative': 2,\n",
       " 'positive': 0,\n",
       " 'sadness': 2,\n",
       " 'surprise': 0,\n",
       " 'trust': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment([\"im\",\"mad\", \"as\",\"hell\"],sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00039-ab72a0b1-b8b0-4879-97fb-b448340225e1",
    "deepnote_cell_type": "markdown",
    "id": "cyL_nj7tQke4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-9d5c7cc5-6819-46e7-be40-375e9fb719d4",
    "deepnote_cell_type": "markdown",
    "id": "Y7aBJeAJKV6l"
   },
   "source": [
    "## Exercise 6  - Sentiment scores normalization\n",
    "\n",
    "### Description\n",
    "Headlines lenght is variable. We should normalize the sentiment scores because longer headlines will tend to have greater scores (because we're summing the sentiment of each word in a sentence) and are not comparable to shorter headlines. Thus, we normalize the score by the square root of the lenght of the sentence (eg. number of words). In Python the square root can be computed as follows:\n",
    "```ipython\n",
    "from math import sqrt\n",
    "sqrt(4)\n",
    ">> 2\n",
    "```\n",
    "### Instructions\n",
    "\n",
    "Write a function `get_normalized_sentiment` with the following requirements:\n",
    "- Should accept 2 arguments\n",
    "    - a list of strings (e.g. tokens)\n",
    "    - a dictionary of dicts such as `sentiment` dict\n",
    "- Should call the `get_sentiment` function to compute sentiment scores.\n",
    "- Normalization is obtained by dividing the sentiment score by the square root of the number of words in a sentence (number of strings in your input list)\n",
    "\n",
    "\n",
    "Example usage:\n",
    "```ipython\n",
    "get_normalized_sentiment([\"im\", \"mad\", \"as\", \"hell\"], sentiment)\n",
    ">> \n",
    "    {\n",
    "        \"anger\": 1.0,\n",
    "        \"anticipation\": 0.0,\n",
    "        \"disgust\": 1.0,\n",
    "        \"fear\": 1.0,\n",
    "        \"joy\": 0.0,\n",
    "        \"negative\": 1.0,\n",
    "        \"positive\": 0.0,\n",
    "        \"sadness\": 1.0,\n",
    "        \"surprise\": 0.0,\n",
    "        \"trust\": 0.0,\n",
    "    }\n",
    "```\n",
    "\n",
    "Note that the example list has 4 words, so the sentiment score is divided by 2 (sqrt of 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00041-6e83ae56-9f7e-4df6-8e99-74722611b763",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1617235446233,
    "id": "q2fJ3R5YQmIo",
    "source_hash": "af986deb"
   },
   "outputs": [],
   "source": [
    "# solve ex6 here\n",
    "def get_normalized_sentiment(strings_list, sentiment):\n",
    "    sentiment_scores = get_sentiment(strings_list,sentiment)\n",
    "    for sentiment in sentiment_scores:\n",
    "        sentiment_scores[sentiment] = sentiment_scores[sentiment] / sqrt(len(strings_list))\n",
    "    return sentiment_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 1.0,\n",
       " 'anticipation': 0.0,\n",
       " 'disgust': 1.0,\n",
       " 'fear': 1.0,\n",
       " 'joy': 0.0,\n",
       " 'negative': 1.0,\n",
       " 'positive': 0.0,\n",
       " 'sadness': 1.0,\n",
       " 'surprise': 0.0,\n",
       " 'trust': 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_normalized_sentiment([\"im\",\"mad\", \"as\",\"hell\"],sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00043-8568437c-4fcc-4387-9e69-6d0e8290f634",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00044-f50782f8-23c4-4e07-a8c0-0bc86c9976dd",
    "deepnote_cell_type": "markdown",
    "id": "Ay52duV7KDVT"
   },
   "source": [
    "## Storing sentiment and normalized sentiment scores\n",
    "\n",
    "With the functions we defined above we can now automate sentiment analysis on any given string. Lets apply it to the `proc_news` dataset and store the result in each dict of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "00046-f02993a4-1eb2-440c-a094-e35699719bc2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3751,
    "execution_start": 1617234963456,
    "id": "bYwHGK5cKDVT",
    "source_hash": "cc070d25"
   },
   "outputs": [],
   "source": [
    "# Run this cell!\n",
    "\n",
    "sentiment_news = []\n",
    "\n",
    "for new in proc_news:\n",
    "    new['sentiment'] = get_sentiment(new['proc_headlinetext'],sentiment)\n",
    "    new['norm_sentiment'] = get_normalized_sentiment(new['proc_headlinetext'],sentiment)\n",
    "    sentiment_news.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": "00046-10b4d36d-64c1-4b7f-a109-81423701a856",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1617235488765,
    "source_hash": "fc4250e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'publishdate': 20131205,\n",
       " 'headlinetext': 'GYfTS tarGeT! GIFT cArdS FOr thE tarGet coRpORatION',\n",
       " 'proc_headlinetext': ['gyfts',\n",
       "  'target',\n",
       "  'gift',\n",
       "  'cards',\n",
       "  'for',\n",
       "  'the',\n",
       "  'target',\n",
       "  'corporation'],\n",
       " 'sentiment': {'anger': 0,\n",
       "  'anticipation': 1,\n",
       "  'disgust': 0,\n",
       "  'fear': 0,\n",
       "  'joy': 1,\n",
       "  'negative': 0,\n",
       "  'positive': 2,\n",
       "  'sadness': 0,\n",
       "  'surprise': 1,\n",
       "  'trust': 1},\n",
       " 'norm_sentiment': {'anger': 0.0,\n",
       "  'anticipation': 0.35355339059327373,\n",
       "  'disgust': 0.0,\n",
       "  'fear': 0.0,\n",
       "  'joy': 0.35355339059327373,\n",
       "  'negative': 0.0,\n",
       "  'positive': 0.7071067811865475,\n",
       "  'sadness': 0.0,\n",
       "  'surprise': 0.35355339059327373,\n",
       "  'trust': 0.35355339059327373}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how the new updated list of dictionaries looks like\n",
    "sentiment_news[42] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00048-6ef0eb5b-a1ad-4dd2-af00-38389b969e14",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00049-b39c204c-010e-439b-9ea5-25ada64f438b",
    "deepnote_cell_type": "markdown",
    "id": "_iy9JfFoKDVU"
   },
   "source": [
    "## Exercise 7 - Group by date\n",
    "### Description\n",
    "We generated a normalized sentiment score which is comparable across diferent headlines - we can start extracting some insights about our data. \n",
    "\n",
    "For instance, we want to know which dates had highest normalized sentiment scores. But before we can do that, we need aggregate all the sentiment scores for a given date.\n",
    "\n",
    "Thus, we should sum the sentiment scores of all headlines of a given `publishdate` and store it in an appropriate data structure - a dictionary.\n",
    "### Instructions\n",
    "\n",
    "Write a function, `get_sentiment_per_date` with the following requirements:\n",
    "- Should accept one list argument (eg. the `sentiment_news` list created before) and a specific date (int) in the format YYYYMMDD (eg. 20130511) (this date is to match the `publishdate` in the headlines)\n",
    "- Returns a dict with the sentiments, and the values are the sum of `norm_sentiment` of all headlines that were published in that specific `publishdate`.\n",
    "\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```ipython\n",
    "get_sentiment_per_date(proc_news, 20130511)\n",
    ">> {\n",
    "    \"anger\": 0.6106834314459479,\n",
    "    \"anticipation\": 0.2773500981126146,\n",
    "    \"disgust\": 0.0,\n",
    "    \"fear\": 0.9440167647792812,\n",
    "    \"joy\": 0.0,\n",
    "    \"negative\": 1.2773500981126147,\n",
    "    \"positive\": 0.35355339059327373,\n",
    "    \"sadness\": 0.0,\n",
    "    \"surprise\": 0.6309034887058883,\n",
    "    \"trust\": 0.35355339059327373,\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "00050-50ea31b4-f721-4e82-8e74-ab0bd14d1aea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1617234967222,
    "source_hash": "c966634a"
   },
   "outputs": [],
   "source": [
    "# solve ex7 here\n",
    "def get_sentiment_per_date(sentiment_news,publishdate):\n",
    "        base = {\n",
    "        \"anger\": 0,\n",
    "        \"anticipation\": 0,\n",
    "        \"disgust\": 0,\n",
    "        \"fear\": 0,\n",
    "        \"joy\": 0,\n",
    "        \"negative\": 0,\n",
    "        \"positive\": 0,\n",
    "        \"sadness\": 0,\n",
    "        \"surprise\": 0,\n",
    "        \"trust\": 0,}\n",
    "\n",
    "        for new in sentiment_news:\n",
    "            if new[\"publishdate\"] == publishdate:\n",
    "                for key in base:\n",
    "                    base[key] += new[\"norm_sentiment\"][key]     \n",
    "        return base \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0.3333333333333333,\n",
       " 'anticipation': 0.0,\n",
       " 'disgust': 0.3333333333333333,\n",
       " 'fear': 0.3333333333333333,\n",
       " 'joy': 0.3333333333333333,\n",
       " 'negative': 0.3333333333333333,\n",
       " 'positive': 0.686886723926607,\n",
       " 'sadness': 0.3333333333333333,\n",
       " 'surprise': 0.35355339059327373,\n",
       " 'trust': 1.0202200572599405}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_per_date(proc_news,20130504)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00051-5aca7155-fa57-4d51-95bf-17fdda0fe4b5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Now that you are done we will show you how to take full advantage of your data. \n",
    "\n",
    "With the function you created in question 7 you could now easily calculate the sentiment per day for all the days and then plot that data to see sentiment trend over time. \n",
    "\n",
    "Read and understand the next lines of code and then run it to see your output and the graphs you can generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00051-0b57d427-0ab4-42f4-a0de-b38f1dfc500f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 34216,
    "execution_start": 1617234967294,
    "source_hash": "e1e97516",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell!\n",
    "\n",
    "unique_dates = set()\n",
    "for new in proc_news:\n",
    "    unique_dates.add(new['publishdate'])\n",
    "\n",
    "aggregate_dict = dict()\n",
    "\n",
    "for date in unique_dates:\n",
    "    aggregate_dict[date] = get_sentiment_per_date(proc_news, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00053-fcc898ac-53be-46fd-9294-6884e01ef98f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We can now access the sentiment of any given date in the `aggregate_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "cell_id": "00052-dae2fe7b-364e-41b4-b401-407e6dde923a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7,
    "execution_start": 1617235528094,
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 1.6208536005380467,\n",
       " 'anticipation': 2.4416197282207275,\n",
       " 'disgust': 0.9712925011878754,\n",
       " 'fear': 2.457913932975586,\n",
       " 'joy': 1.2431389634796237,\n",
       " 'negative': 1.5743151903434027,\n",
       " 'positive': 5.05426278222002,\n",
       " 'sadness': 0.6697811566101117,\n",
       " 'surprise': 1.8584889281968042,\n",
       " 'trust': 3.8802714320724023}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_dict[20160512] # Run this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cell_id": "00054-28c03b5a-573e-481c-a267-c5e839a6c859",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1617235540357,
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0.5901864791725766,\n",
       " 'anticipation': 3.2630550666635068,\n",
       " 'disgust': 0.30151134457776363,\n",
       " 'fear': 1.2250311570836736,\n",
       " 'joy': 0.5901864791725766,\n",
       " 'negative': 2.637959167854542,\n",
       " 'positive': 5.459300392757524,\n",
       " 'sadness': 0.9681780112444303,\n",
       " 'surprise': 0.30151134457776363,\n",
       " 'trust': 2.9191963370471123}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_dict[20160513] # Run this cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00052-34a139be-cf77-4788-9ce4-6e5cf5bbe4f7",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Visualization time\n",
    "\n",
    "If you have sucessfuly completed all the exercises, below there's an example of could be done with the sentiment information you just computed for 200k different cryptocurrency-related headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cell_id": "00053-14764ccd-422b-4bf2-8742-4760957772d5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 36747,
    "execution_start": 1617235014284,
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_sentiment_over_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/miguelguerra/Documents/NOVA SBE/Courses/S2/Introduction to Programming/Extra Exercises/Functions/exercises_functions.ipynb Cell 58\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miguelguerra/Documents/NOVA%20SBE/Courses/S2/Introduction%20to%20Programming/Extra%20Exercises/Functions/exercises_functions.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run this!\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miguelguerra/Documents/NOVA%20SBE/Courses/S2/Introduction%20to%20Programming/Extra%20Exercises/Functions/exercises_functions.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plot_sentiment_over_time(get_sentiment_per_date, sentiment_news)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_sentiment_over_time' is not defined"
     ]
    }
   ],
   "source": [
    "# Run this!\n",
    "plot_sentiment_over_time(get_sentiment_per_date, sentiment_news)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "assignment_3 copy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "d12feb28-d14d-46e3-afac-3b97366bb219",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
